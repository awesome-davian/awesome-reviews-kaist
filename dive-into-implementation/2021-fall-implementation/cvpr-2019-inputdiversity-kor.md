---
description: Xie et al. / Improving transferability of adversarial examples with input diversity / CVPR 2019
---



# Diversity Input Method \[Kor\]

**[English version](cvpr-2019-inputdiversity-eng.md)** of this article is available.



## 1. Introduction

### âœ”ì ëŒ€ì  ê³µê²©(Adversarial Attack)

â€‹	**ì ëŒ€ì  ê³µê²©**ì´ë€, ê·¸ë¦¼ê³¼ ê°™ì´ ì´ë¯¸ì§€ì— ë¯¸ì„¸í•œ _ì¡ìŒ (noise)_ì„ ì˜ë„ì ìœ¼ë¡œ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì˜ **ì˜ëª»ëœ ì˜ˆì¸¡**ì„ ìœ ë„í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ì ëŒ€ì  ê³µê²©ì€ ê³µê²©ìê°€ íƒ€ê²Ÿ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ íŠ¹ì •í•œ í´ë˜ìŠ¤ë¡œ ìœ ë„í•˜ëŠ” ê³µê²©ì¸ í‘œì  ê³µê²© (targeted attack)ê³¼, ìœ ë„í•˜ì§€ ì•Šê³  ë‹¨ìˆœíˆ ì˜ˆì¸¡ì„ í‹€ë¦¬ê²Œ í•˜ëŠ” ë¬´í‘œì  ê³µê²© (non-targeted attack)ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.

![](../../.gitbook/assets/31/duck.png)

â€‹	ê³µê²©í•˜ê³ ì í•˜ëŠ” ëª¨ë¸ì— ì ‘ê·¼ì´ ê°€ëŠ¥í•œ _í™”ì´íŠ¸ ë°•ìŠ¤ (white box)_ ê³µê²©ì€ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜(weight)ì— ì ‘ê·¼í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì…ë ¥ ì´ë¯¸ì§€ì— ëŒ€í•œ ì†ì‹¤ í•¨ìˆ˜ (loss function)ì˜ **ê²½ì‚¬ë„(gradient)**ë¥¼ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ êµ¬í•œ ê²½ì‚¬ë„ëŠ” ì ëŒ€ì  ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ë•Œ ì´ìš©ë©ë‹ˆë‹¤. 



### âœ”ì „ì´ ê¸°ë°˜ ì ëŒ€ì  ê³µê²©(Transfer-Based Adversarial-Attack)

â€‹	ê³µê²©í•˜ê³ ì í•˜ëŠ” ëª¨ë¸ì— **_ì ‘ê·¼ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°_**ë¼ë©´, ì ëŒ€ì  ì´ë¯¸ì§€ì˜ **ì „ì´ì„±**ì„ ì´ìš©í•˜ì—¬ **ì „ì´ ê¸°ë°˜ ì ëŒ€ì  ê³µê²©**ì„ ì‹œë„í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” ì†ŒìŠ¤ ëª¨ë¸ì— í™”ì´íŠ¸ ë°•ìŠ¤ ê³µê²©ì„ ê°€í•´ ìƒì„±í•œ ì ëŒ€ì  ì´ë¯¸ì§€ë¥¼ í†µí•´ íƒ€ê²Ÿ ëª¨ë¸ë„ ê³µê²©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì „ì´ ê¸°ë°˜ ì ëŒ€ì  ê³µê²© ì„±ê³µë¥ ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” ì ëŒ€ì  ì´ë¯¸ì§€ í˜•ì„± ì‹œ, ì ëŒ€ì ì¸ ì´ë¯¸ì§€ê°€ ì†ŒìŠ¤ ëª¨ë¸ì— ì˜ì¡´í•˜ì—¬ ì†ŒìŠ¤ ëª¨ë¸ì—ì„œë§Œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ê²Œ ë˜ëŠ” _**ê³¼ì í•©(overfitting)**_ í˜„ìƒì„ ë°©ì§€í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

â€‹	**Diversity Input Method (DI ê¸°ë²•)** ì€ **ëœë¤ í¬í‚¤ ë³€í™˜**ê³¼ **ëœë¤ íŒ¨ë”©**ì„ ê±°ì¹œ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ì ëŒ€ì  ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ëŠ” ì ëŒ€ì ì¸ ì´ë¯¸ì§€ëŠ” í¬í‚¤ì™€ ìœ„ì¹˜ê°€ ë³€í™”í•˜ë”ë¼ë„ ì ëŒ€ì ìœ¼ë¡œ ì‘ìš©í•´ì•¼ í•œë‹¤ëŠ” ê°€ì •ì—ì„œ ì°©ì•ˆí•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì ëŒ€ì  ì´ë¯¸ì§€ê°€ ì†ŒìŠ¤ ëª¨ë¸ì— _ê³¼ì í•©_ ë˜ëŠ” í˜„ìƒì„ ë°©ì§€í•˜ì—¬, ì—¬ëŸ¬ ëª¨ë¸ì—ì„œ ì ëŒ€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤. 



## 2. Method

### Diversity Input Methodâœ¨

â€‹	DI ê¸°ë²•ì˜ í•µì‹¬ ì•„ì´ë””ì–´ëŠ” **ëœë¤ í¬í‚¤ ë³€í™˜(randomly resizing)**ê³¼ **ëœë¤ íŒ¨ë”©(random padding)** ëœ ì´ë¯¸ì§€ì˜ ê²½ì‚¬ë„ë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ì ëŒ€ì  ì´ë¯¸ì§€ê°€ ì†ŒìŠ¤ ëª¨ë¸ì— ì˜ì¡´í•˜ëŠ” í˜„ìƒì„ ë°©ì§€í•œ ê²ƒì…ë‹ˆë‹¤. ì´ ë³€í™˜ ê³¼ì •ì„ DI ë³€í™˜ (DI transform) ì´ë¼ê³  í•˜ê² ìŠµë‹ˆë‹¤. ì•„ë˜ ì´ë¯¸ì§€ëŠ” ì›ë³¸ ì´ë¯¸ì§€ì™€ DI ë³€í™˜ í›„ì˜ ì´ë¯¸ì§€ë¥¼ ë¹„êµí•œ ê²ƒ ì…ë‹ˆë‹¤.

<p align="center"> 	<img src="../../.gitbook/assets/31/di.png"> </p>

ë³¸ ë…¼ë¬¸ì—ì„œ DI ë³€í™˜ì„ êµ¬í˜„í•œ ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ :

* **ëœë¤ í¬í‚¤ ë³€í™˜** : ì´ë¯¸ì§€ë¥¼ rnd Ã— rnd Ã— 3 ë¡œ í¬ê¸° ë³€í™˜ (rnd âˆˆ [299, 330))

* **ëœë¤ íŒ¨ë”©** : ì´ë¯¸ì§€ë¥¼ 330 Ã— 330 Ã— 3 ì´ ë˜ë„ë¡ ìƒí•˜ì¢Œìš°ì— ëœë¤í•˜ê²Œ íŒ¨ë”©



â€‹	ë³¸ ë…¼ë¬¸ì—ì„œëŠ” TensorFlowë¥¼ ì‚¬ìš©í•˜ì˜€ìœ¼ë©°, DI ë³€í™˜ ì´í›„ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ 330 Ã— 330 Ã— 3ìœ¼ë¡œ ê³ ì •ì‹œì¼œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. (ì´í›„, ëª¨ë¸ ì…ë ¥ ì‚¬ì´ì¦ˆì— ë§ì¶° ë‹¤ì‹œ ì´ë¯¸ì§€ í¬ê¸°ë³€í™˜ì„ ì§„í–‰í•©ë‹ˆë‹¤.) ì €ëŠ” **PyTorch**ë¥¼ ì´ìš©í•´ ë…¼ë¬¸ì˜ _ëœë¤ í¬í‚¤ ë³€í™˜_ê³¼ _ëœë¤ íŒ¨ë”©_ì˜ ê³¼ì •ì„ ìœ ì§€í•˜ë˜, DI ë³€í™˜ ì´í›„ì˜ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆì™€ ë™ì¼í•˜ë„ë¡ ì½”ë“œë¥¼ êµ¬í˜„í•˜ì—¬ í›„ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì¹˜ì§€ ì•Šì•„ë„ ë˜ë„ë¡ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

â€‹	DI ë³€í™˜ì€ ì´ë¯¸ ì•Œë ¤ì§„ ì „ì´ ê¸°ë°˜ ì ëŒ€ì  ê³µê²©(I-FGSM, MI-FGSM) ê³¼ í•¨ê»˜ ì´ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤. DI ë³€í™˜ì— I-FGSM ê³µê²© ê¸°ë²•ì„ ì´ìš©í•˜ì—¬ ê³µê²©í•˜ëŠ” ê²½ìš°, **DI-FGSM** ì´ë¼ê³  ì¹­í•˜ê² ìŠµë‹ˆë‹¤. ì•„ë˜ì˜ Related work ì—ì„œ ê°ê°ì˜ ê³µê²© ë°©ë²•ì— ëŒ€í•´ì„œë„ ì†Œê°œí•˜ê² ìŠµë‹ˆë‹¤.



### Related workâœ¨

#### 1) Iterative Fast Gradient Sign Method (I-FGSM)

â€‹	Fast gradient sign method(FGSM)ì€ ì…ë ¥ ì´ë¯¸ì§€ Xì™€ ì‹¤ì œ í´ë˜ìŠ¤ y(true) ì— ëŒ€í•´ ì†ì‹¤ í•¨ìˆ˜ L(X,y(true))ê°€ ì¦ê°€í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ X ì˜ ê° í”½ì…€ì„ Îµë§Œí¼ ë³€í™”ì‹œì¼œ ì ëŒ€ì ì¸ ì´ë¯¸ì§€ X^{adv}ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
$$
X^{adv}=X+ÎµÂ·sign(âˆ‡_X L(X,y^{true})).
$$
â€‹	ê° í”½ì…€ì„  Î± ë§Œí¼ ë³€í™”ì‹œí‚¤ëŠ” FGSM ê³µê²©ì„ ë°˜ë³µì ìœ¼ë¡œ ì‹œí–‰í•œ ê²ƒì´ Iterative Fast Gradient Sign Method (I-FGSM)ì…ë‹ˆë‹¤. 
$$
X_0^{adv}=X,
$$

$$
X_{n+1}^{adv}=Clip_X^Îµ(X_n^{adv}+Î±Â·sign(âˆ‡_X L(X_n^{adv},y^{true})).
$$



#### 2) ëª¨ë©˜í…€ ì´ìš© ê¸°ë²• (MI-FGSM)

â€‹	ì†ŒìŠ¤ ëª¨ë¸ì— ëŒ€í•œ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ëª¨ë©˜í…€(momentum)ì„ ì´ìš©í•˜ëŠ” ë°©ë²•ì¸ ëª¨ë©˜í…€ ì´ìš© ê¸°ë²• (MI-FGSM)ì´ ìˆìŠµë‹ˆë‹¤. MI-FGSMì€ I-FGSMê³¼ ê°™ì´ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰ë˜ë©°, ì²˜ìŒë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ê²½ì‚¬ë„(gt) ì •ë³´ë¥¼ ì¶•ì í•˜ì—¬ ì ëŒ€ì  ì´ë¯¸ì§€ ê°±ì‹ ì— ì‚¬ìš©í•©ë‹ˆë‹¤. ê°±ì‹ ì— ì†ì‹¤í•¨ìˆ˜ì˜ ë¶€í˜¸ê°€ ì•„ë‹Œ, gtì˜ ë¶€í˜¸ë¥¼ ì´ìš©í•œë‹¤ëŠ” ì ì—ì„œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.
$$
g_{n+1}= Î¼g_n + {âˆ‡_X L(X_n^{adv},y^{true} )\over ||âˆ‡_X L(X_n^{adv},y^{true})||_1 },
$$

$$
X_{n+1}^{adv}=X_{n}^{adv} +Î±Â·sign(g_{t+1}).
$$

â€‹	ê²½ì‚¬ë„ë¥¼ ì¶•ì í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì¢‹ì§€ ì•Šì€ ì§€ì—­ì  ìµœì†Œì (poor local maxima)ì— ë¹ ì§€ì§€ ì•Šê²Œ ë„ì™€ì£¼ë©°, I-FGSMì— ë¹„í•´ ë°˜ë³µì ìœ¼ë¡œ ê°±ì‹ ë˜ëŠ” ì ëŒ€ì ì¸ ë³€í™”ì˜ ë°©í–¥ì´ ë¹„ìŠ·í•˜ì—¬ ì•ˆì •ì ì…ë‹ˆë‹¤. ë”°ë¼ì„œ MI-FGSMì€ I-FGSMë³´ë‹¤ ì¢‹ì€ ì „ì´ì„±ì„ ë³´ì…ë‹ˆë‹¤.



## 3. Implementation

* Use **Python** language, version >= 3.6 : 3.6 ì´ìƒ ë²„ì „ì˜ íŒŒì´ì¬ ìš”êµ¬

* Use **PyTorch** : ì½”ë“œ êµ¬í˜„ê³¼ì •ì— PyTorch ì‚¬ìš©

* Use _manual seed_ : ëœë¤ì„±ì„ ê³ ì •í•˜ê¸° ìœ„í•´ ì‚¬ìš© (ì•„ë˜ example codeì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.)

  

### ğŸ”¨ Environment

â€‹	DI ê¸°ë²• êµ¬í˜„ê³¼ì •ì—ì„œ í•„ìš”í•œ í™˜ê²½ **(env_di-fgsm.yml)**ì„ yml íŒŒì¼ë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì•„ë‚˜ì½˜ë‹¤ ê°€ìƒí™˜ê²½ì„ ì´ìš©í•˜ë©°, ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ í™˜ê²½ì„¤ì •ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# Environment setup using conda
conda env create -f env_di-fgsm.yml
```



### ğŸ“‹DI-FGSM

â€‹	ì´ íŒŒì¼ì—ëŠ”, DI-FGSMì´ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.   _**ì£¼ì„**_ì„ ì´ìš©í•´ ì „ë°˜ì ì¸ ì½”ë“œ ì„¤ëª…ì„ í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ì†Œê°œë  ì˜ˆì‹œ íŒŒì¼ Transfer Attack.py ì—ì„œ ì´ìš©í•œ CIFAR-10 ì´ë¯¸ì§€ (size : 32, 32) ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì‹œë¥¼ ë“¤ì–´ tensors ì˜ í¬ê¸°ë¥¼ ë‚˜íƒ€ëƒˆìŠµë‹ˆë‹¤.

â€‹	class DIFGSM ë‚´ì— ìˆëŠ” **_diverse_input_** í•¨ìˆ˜ ë¶€ë¶„ì´ DI-FGSMì˜ í•µì‹¬ ë¶€ë¶„ì¸ DI transform ì´ ì¼ì–´ë‚˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. **ëœë¤ í¬í‚¤ ë³€í™˜** ê³¼ **ëœë¤ íŒ¨ë”©** ë¶€ë¶„ì´ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. _forward_ í•¨ìˆ˜ì—ì„œ _diverse_input_ í•¨ìˆ˜ í˜¸ì¶œ ì´í›„, ì—­ì „íŒŒ(backpropagation) ì´ ì¼ì–´ë‚©ë‹ˆë‹¤.

```python
## DI-FGSM : DIFGSM.py

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.transforms import InterpolationMode
import torchgeometry as tgm
from attack import Attack


class DIFGSM(Attack):

    def __init__(self, model, eps=8/255, alpha=2/255, steps=20, di_pad_amount=31, di_prob=0.5):
        super().__init__("DIFGSM", model)
        self.eps = eps # Maximum change in one pixel for total step (range 0-255)
        self.steps = steps # number of di-fgsm steps
        self.alpha = alpha # Maximum change in one pixel for one step (range 0-255)
        self.di_pad_amount = di_pad_amount # Maximum value that can be padded
        self.di_prob = di_prob # Probability of deciding whether to apply DI transform or not
        self._supported_mode = ['default', 'targeted'] # deciding targeted attack or not

    def diverse_input(self, x_adv):
        x_di = x_adv # size : [24,3,32,32]
        h, w = x_di.shape[2], x_di.shape[3] # original image size, h: 32, w: 32
        # random value that be padded
        pad_max = self.di_pad_amount - int(torch.rand(1) * self.di_pad_amount) # pad_max : 2
        # random value that be padded left
        pad_left = int(torch.rand(1) * pad_max) # pad_left : 1
        # random value that be padded right
        pad_right = pad_max - pad_left # pad_right : 1
        # random value that be padded top
        pad_top = int(torch.rand(1) * pad_max) # pad_top : 1
        # random value that be padded bottom
        pad_bottom = pad_max - pad_top  # pad_bottom : 1

        # four vertices of the original image
        # tensor([[[ 0.,  0.], [31.,  0.], [31., 31.], [ 0., 31.]]])
        points_src = torch.FloatTensor([[
            [0, 0], [w - 1, 0], [w - 1 + 0, h - 1 + 0], [0, h - 1 + 0],
        ]]) 

        # four vertices of the image after DI transform
        # tensor([[[ 1.,  1.], [30.,  1.], [30., 30.], [ 1., 30.]]])
        points_dst = torch.FloatTensor([[
            [pad_left, pad_top], [w - pad_right - 1, pad_top],
            [w - pad_right - 1, h - pad_bottom - 1], [pad_left, h - pad_bottom - 1],
        ]]) 

        # Matrix used in the transformation process
        # tensor([[[0.9355, 0.0000, 1.0000], [0.0000, 0.9355, 1.0000], [0.0000, 0.0000, 1.0000]]])
        M = tgm.get_perspective_transform(points_src, points_dst) 
        
        # The image is resized and padded so that the vertices of the original image go to the new vertices.
        x_di = tgm.warp_perspective(x_di, torch.cat(x_di.shape[0] * [M]).cuda(), dsize=(w, h)).cuda()
        x_di = transforms.Resize((w, h), interpolation=InterpolationMode.NEAREST)(x_di)
        
        # If the random value is less than or equal to di_prob, di conversion does not occur.
        cond = torch.rand(x_adv.shape[0]) < self.di_prob
        
        cond = cond.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)
        x_di = torch.where(cond.cuda(), x_di, x_adv)
        return x_di

    def forward(self, images, labels):
        """
        Overridden.
        """
        images = images.clone().detach().to(self.device)
        labels = labels.clone().detach().to(self.device)

        if self._targeted: # targeted attack case, get target label
            target_labels = self._get_target_label(images, labels)

        loss = nn.CrossEntropyLoss() # use Cross-Entropy loss for classification
        adv_images = images.clone().detach()


        for _ in range(self.steps):
            adv_images.requires_grad = True
            outputs = self.model(self.diverse_input(adv_images)) # after DI transform image

            # Calculate loss
            if self._targeted:
                cost = -loss(outputs, target_labels) # targeted attack case, use -loss function
            else:
                cost = loss(outputs, labels) # else, (untargeted attack case), use +loss function

            # Update adversarial images
            grad = torch.autograd.grad(cost, adv_images,
                                       retain_graph=False, create_graph=False)[0]

            grad = grad / torch.mean(torch.abs(grad), dim=(1,2,3), keepdim=True)

            adv_images = adv_images.detach() + self.alpha*grad.sign() # I-fgsm step
            delta = torch.clamp(adv_images - images, min=-self.eps, max=self.eps) # limiting changes beyond epsilon
            adv_images = torch.clamp(images + delta, min=0, max=1).detach()

        return adv_images
```



### ğŸ“‹Example code

_**Transfer Attack.py**_ ì½”ë“œì—ì„œ, DI-FGSMì„ ì´ìš©í•œ Transfer Attackì˜ ì„±ëŠ¥ì„ ì‹¤í—˜í•´ë³´ì•˜ìŠµë‹ˆë‹¤. 

##3 : Source ëª¨ë¸ì˜ ê³µê²© ê³¼ì • ë° ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. _atk = DIFGSM(model, eps=16 / 255, alpha=2 / 255, steps=10, di_pad_amount=5)_ì™€ ê°™ì´ ê³µê²©ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

##5, ##6 : Target ëª¨ë¸ì— validation setìœ¼ë¡œ ì„±ëŠ¥ì„ ì‹œí—˜í•œ **clean accuracy**ì™€, ##3ì—ì„œ ë§Œë“¤ì–´ì§„ ì ëŒ€ì ì¸ ì´ë¯¸ì§€ë¡œ ì„±ëŠ¥ì„ ì‹œí—˜í•œ **robust accuracy**ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

#### exampleğŸš€ 

```python
##0 Example - Transfer Attack.py

from torch.utils.data import DataLoader, TensorDataset
import torchvision.utils
import torchvision.datasets as dsets
import random
import warnings
warnings.filterwarnings('ignore')
from models import Source, Target
from DIFGSM import *


##1 check version
print("PyTorch", torch.__version__)
print("Torchvision", torchvision.__version__)

my_seed = 7777
random.seed(my_seed)
torch.manual_seed(my_seed)
torch.cuda.manual_seed(my_seed)
torch.cuda.manual_seed_all(my_seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

##2 Load Data
batch_size = 24

cifar10_train = dsets.CIFAR10(root='./data', train=True,
                              download=True, transform=transforms.ToTensor())
cifar10_test  = dsets.CIFAR10(root='./data', train=False,
                              download=True, transform=transforms.ToTensor())

train_loader = torch.utils.data.DataLoader(cifar10_train,
                                           batch_size=batch_size,
                                           shuffle=True)
test_loader = torch.utils.data.DataLoader(cifar10_test,
                                          batch_size=batch_size,
                                          shuffle=False)


##3 Attack Source Model & Save Adversarial Images
model = Source()
model.load_state_dict(torch.load("./data/source.pth"))
model = model.eval().cuda()

atk = DIFGSM(model, eps=16 / 255, alpha=2 / 255, steps=10, di_pad_amount=5)
atk.set_return_type('int') # Save as integer.
print('\n#################Source Model#################')
atk.save(data_loader=test_loader, save_path="./data/cifar10_DIFGSM.pt", verbose=True)


##4 Load Adversarial Images & Attack Target Model
adv_images, adv_labels = torch.load("./data/cifar10_DIFGSM.pt")
adv_data = TensorDataset(adv_images.float()/255, adv_labels)
adv_loader = DataLoader(adv_data, batch_size=128, shuffle=False)

model = Target().cuda()
model.load_state_dict(torch.load("./data/target.pth"))


##5 Target Model : Clean Accuracy
print('#################Target Model#################')
model.eval()
correct = 0
total = 0

for images, labels in test_loader:
    images = images.cuda()
    outputs = model(images)
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels.cuda()).sum()

print('Standard accuracy: %.2f %%' % (100 * float(correct) / total))


##6 Target Model : Robust Accuracy
model.eval()
correct = 0
total = 0

for images, labels in adv_loader:
    images = images.cuda()
    outputs = model(images)
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels.cuda()).sum()

print('Robust accuracy: %.2f %%' % (100 * float(correct) / total))

```

#### resultsğŸš€ 

â€‹	Target ëª¨ë¸ì— _validation set_ìœ¼ë¡œ ì„±ëŠ¥ì„ ì‹œí—˜í•œ **clean accuracy**ì˜ ì„±ëŠ¥ì€ 87.26 %  ë¡œ ë¹„êµì  ë†’ì€ ë¹„êµ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. 

â€‹	ë°˜ë©´ Source ëª¨ë¸ì„ í†µí•´ DI-FGSMìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ì ëŒ€ì ì¸ ì´ë¯¸ì§€ë¡œ Target ëª¨ë¸ ì„±ëŠ¥ì„ ì‹œí—˜í•œ robust accuracyëŠ” 38.87 %ë¡œ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì´ë©°, ì„±ê³µì ì¸ ì „ì´ ê¸°ë°˜ ì ëŒ€ì  ê³µê²©ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
System :  3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]
Nunpy :  1.19.2
PyTorch :  1.9.0
Files already downloaded and verified
Files already downloaded and verified

#################Source Model#################
- Save progress: 100.00 % / Accuracy: 0.03 % / L2: 2.26292 (0.047 it/s) 	
- Save complete! 

#################Target Model#################
Standard accuracy: 87.26 %
Robust accuracy: 38.87 %

Process finished with exit code 0

```



## Author / Reviewer information

### AuthorğŸ˜

**ê¹€í¬ì„  \(Hee-Seon Kim\)**

* KAIST EE 
* https://github.com/khslily98
* hskim98@kaist.ac.kr



### ReviewerğŸ˜

1. Korean name \(English name\): Affiliation / Contact information
2. Korean name \(English name\): Affiliation / Contact information
3. ...

## Reference & Additional materials

1. Citation of this paper
2. Official \(unofficial\) GitHub repository
3. Citation of related work
4. Other useful materials
5. ...
