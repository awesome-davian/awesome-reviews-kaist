---
description: Soh et al. / Meta-Transfer Learning for Zero-shot Super Resolution / CVPR 2020
---

# Meta-Transfer Learning for Zero-shot Super Resolution \[Korean\]

## Preface

### Transfer Learningì´ëž€?

Transfer Learningì´ëž€ ì•„ì£¼ í° ë°ì´í„°ì…‹ì— í›ˆë ¨ëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§€ê³  ì™€ì„œ ìš°ë¦¬ê°€ í•´ê²°í•˜ê³ ìž í•˜ëŠ” ê³¼ì œì— ë§žê²Œ ìž¬ë³´ì •í•´ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ë¹„êµì  ì ì€ ìˆ˜ì˜ ë°ì´í„°ë¥¼ ê°€ì§€ê³ ë„ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê³¼ì œë¥¼ í•´ê²°í•  ìˆ˜ ìžˆëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¬ ìˆ˜ ìžˆëŠ” ê²ƒìž…ë‹ˆë‹¤.

### Meta Learningì´ëž€?

Meta learningì´ëž€ í•™ìŠµì— ëŒ€í•œ í•™ìŠµì„ ë§í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” í•™ìŠµì„ ìœ„í•´ ì£¼ì–´ì§„ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì´ë‚˜ íŠ¹ì§•ì„ ì°¾ê³  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ê·¸ íŠ¹ì§•ì„ ì°¾ëŠ” ê²ƒìž…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ëŠ” ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” learningë³´ë‹¤ í•œ ë‹¨ê³„ ìœ„ì¸, Hyper-parameterì— ëŒ€í•´ì„œ ì í•©í•œ ê°’ì„ ì°¾ëŠ” Learningì„ ì§„í–‰í•©ë‹ˆë‹¤.



##  1. Problem definition

ë³¸ ë…¼ë¬¸ì˜ MZSR(Meta-Transfer Learning for Zero-shot Super Resolution)ì€ í•œ ìž¥ì˜ ì‚¬ì§„ì—ì„œ ì•½ê°„ì˜ ì—…ë°ì´íŠ¸ë§Œì„ ìˆ˜í–‰í•˜ì—¬ ìš°ìˆ˜í•œ í•´ìƒë„ ë³µì› ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ë°©ë²•ìž…ë‹ˆë‹¤.
íŠ¹ì§•ì€ Transfer-learningê³¼ Meta-learningì„ ì´ëŸ¬í•œ Zero-shot Super Resolution ë¶„ì•¼ì— ì‚¬ìš©í–ˆë‹¤ëŠ” ì ì¸ë°ìš”, ìš°ì„  Transfer learningì„ ì´ìš©í•˜ì—¬ ë§Žì€ ìˆ˜ì˜ ì™¸ë¶€
ì´ë¯¸ì§€ë¡œë¶€í„° ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸(pre-trained model)ì„ ì´ìš©í•˜ì—¬ ì¶”ê°€ì ìœ¼ë¡œ Fine-tuneì„ ì§„í–‰í•  ìˆ˜ ìžˆë„ë¡ í•©ë‹ˆë‹¤.
ë‹¤ë§Œ, ì´ Fine-tuneì„ ì§„í–‰í•  ë•Œ, Meta-learningì„ ì´ìš©í•´ì„œ ë‹¤ì–‘í•œ ì»¤ë„(kernel)ì— ëŒ€í•´ì„œ ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìžˆê²Œë” í•˜ëŠ” ê²ƒì´ íŠ¹ì§•ìž…ë‹ˆë‹¤.
ì´ Meta-learning ê³¼ì •ì„ ë§ˆì¹˜ê³  ë‚˜ë©´, ì–´ë–¤ ì´ë¯¸ì§€ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ì–´ë–¤ internal data repetition ì •ë³´ë¥¼ ì´ìš©í•´ì„œ í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ê·¸ëŸ° Zero-shot ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµì´ ë™ìž‘í•  ë•Œ, ì´ì™€ ê°™ì´
ì•½ê°„ì˜ ì—…ë°ì´íŠ¸ë§Œì„ ì´ìš©í•´ë„ ë¹ ë¥´ê²Œ ì˜ë„í–ˆë˜ íŠ¹ì • ì»¤ë„ì— ë§žëŠ” ê·¸ëŸ° ê°€ì¤‘ì¹˜ë¥¼ ì°¾ì•„ì„œ í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

![Figure 1: Super-resolved results of "image050" in Urban100.](../../.gitbook/assets/FIg1.PNG)

## 2. Motivation

ì¦‰ ì¼ë°˜ì ìœ¼ë¡œ ì´ ZSSRì€ í”ížˆ ìš°ë¦¬ê°€ ì•Œê³  ìžˆëŠ” Zero-shot Super-resolution ë°©ë²•ì¸ë°ìš”, ì´ëŸ° ê²½ìš°ì—ëŠ” ìžê¸° ìžì‹  ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ì—¬ëŸ¬ë²ˆ í•™ìŠµ ê³¼ì •ì„ ê±°ì³ì•¼í•˜ê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ ì•½ 3000ë²ˆì˜ ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•œë°ìš”, ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” MZSRì„ ì´ìš©í•˜ê²Œ ë˜ë©´, Transferì™€ Meta-learningì„ ì‚¬ì „ì— ë¯¸ë¦¬ ì´ìš©í•´ë†“ê³  ì‹¤ì œë¡œ meta-test ê³¼ì •ì—ì„œ ë‹¨ìˆœížˆ í•œë²ˆ, ê·¸ë¦¬ê³  ë§Žê²ŒëŠ” 10ë²ˆ ì •ë„ì˜ ì—…ë°ì´íŠ¸ë§Œ ìˆ˜í–‰í•˜ë”ë¼ë„, ê°€ì¤‘ì¹˜ê°€ ì´ ì´ë¯¸ì§€ì— ë§žê²Œ ì ì ˆí•˜ê²Œ íŠ¹ì • ì»¤ë„ì— ìž˜ ë¶€í•©í•  ìˆ˜ ìžˆë„ë¡ í•™ìŠµì´ ë˜ê¸° ë•Œë¬¸ì—, ì ì€ ì—…ë°ì´íŠ¸ë§Œ ê°€ì§€ê³ ë„ ë¹ ë¥´ê²Œ ê°€ì¤‘ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ìžˆì–´ì„œ Zero-shot Super-resolutionë¥¼ ìœ„í•œ ëª¨ë¸ì„ ë¹ ë¥´ê²Œ ë§Œë“¤ ìˆ˜ ìžˆë‹¤ëŠ” ê²ƒì´ ìž¥ì ìž…ë‹ˆë‹¤.

### Related work

#### 1) CNNê¸°ë°˜ ì ‘ê·¼ë°©ì‹
ìµœê·¼ì—ëŠ” CNNê¸°ë°˜ì˜ ì ‘ê·¼ë°©ë²•ì´ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìžˆì–´ì„œ ë§Žì´ ì‚¬ìš©ë˜ê³  ìžˆëŠ”ë°ìš”, ì´ëŠ” ì €í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ë„¤íŠ¸ì›Œí¬ì— ëŒ€ìž…í•˜ì—¬ ë†’ì€ í•´ìƒë„ë¡œ ë°˜í™˜í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.
ë¬¼ë¡ , ì´ Neural Networkì˜ ì¢…ë¥˜ì— ë”°ë¼ì„œ ì €í•´ìƒë„ì˜ ì´ë¯¸ì§€ë¥¼ Bicubic ë“±ì„ ì´ìš©í•˜ì—¬ í¬ê¸°ë¥¼ í‚¤ìš´ ë‹¤ìŒì— ì´ ì´ë¯¸ì§€ë¥¼ Neural Networkì— ë„£ì–´ì„œ ê³ í•´ìƒë„ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
ì´ë•Œ, ê³ í•´ìƒë„ ì´ë¯¸ì§€ë“¤ì„ íŠ¹ì • kernalì„ ì´ìš©í•˜ì—¬ Blurì²˜ë¦¬ë¥¼ í•˜ê³ , Downsampling, Noise ì¶”ê°€ ê³¼ì •ì„ ê±°ì³ ì €í•´ìƒë„ë¡œ ë§Œë“¤ì–´ì„œ Train dataë¡œì¨ ì‚¬ìš©í•©ë‹ˆë‹¤.
ë‹¤ë§Œ, Downsampling ê³¼ì •ì—ì„œ bicubicê³¼ ê°™ì€ ìž˜ ì•Œë ¤ì§„ kernalë§Œì„ ì´ìš©í•˜ë©´ non-bicubic ì¼€ì´ìŠ¤ì— ëŒ€í•˜ì—¬ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” **domain gap** ë¬¸ì œê°€ ë°œìƒí•˜ê²Œ ë©ë‹ˆë‹¤.

![Figure 2: CNNê¸°ë°˜ ì ‘ê·¼ë°©ì‹.](../../.gitbook/assets/Fig3.PNG)
![Figure 3: CNNê¸°ë°˜ ì ‘ê·¼ë°©ì‹ì˜ ê³¼ì •.](../../.gitbook/assets/Fig4.PNG)

#### 2) SISR(Single Image Super-Resolution)

ì´ ë¶„ì•¼ì— ëŒ€í•´ì„œ ê¸°ë³¸ì ì¸ ë‚´ìš©ë¶€í„° ì•Œê¸° ìœ„í•´ì„œ SISR(Single Image Super-Resolution)ì— ëŒ€í•´ì„œ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
ì´ ë¶„ì•¼ëŠ” í•œ ìž¥ì˜ ì €í•´ìƒë„ ì´ë¯¸ì§€(LR)ê°€ í…ŒìŠ¤íŠ¸ íƒ€ìž„ì— ì£¼ì–´ì¡Œì„ ë•Œ, ì´ë¥¼ ê³ í•´ìƒë„ ì´ë¯¸ì§€(HR)ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.
í”½ì…€ ì—¬ëŸ¬ê°€ì§€ ê°’ë“¤ì´ ì¡´ìž¬í•œë‹¤ê³  í–ˆì„ ë•Œ, ì´ í”½ì…€ì˜ ìˆ˜ë¥¼ ëŠ˜ë¦°ë‹¤ê³  í•˜ë©´, ì¦‰ ê³ í•´ìƒë„ì˜ ì´ë¯¸ì§€ë¡œ ë°”ë€ë‹¤ê³  í•˜ë©´,
ë‹¤ì–‘í•œ ë°©ë²•(1D nearest-neighbor, Linear, Cubic, 2D nearest-neighbor, Bilinear, Bicubic)ì„ ì´ìš©í•˜ì—¬ í”½ì…€ ê°’ì„ ìƒì„±í•©ë‹ˆë‹¤.
ì—¬ê¸°ì„œ Cubicì€ 3ì°¨í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ëŠ” ë‚´ìš©ì´ë¼ê³  ë³´ì‹œë©´ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ê¸°ì¡´ì— ì¡´ìž¬í•˜ëŠ” ê°ê°ì˜ sample ê°’ì„ ì°¸ê³ í•˜ì—¬ ì´ ì¤‘ê°„ ì§€ì ì˜ í”½ì…€
ê°’ì„ ê²°ì •í•˜ëŠ” ë°©ì‹ì´ ê°€ìž¥ ì „í†µì ì´ë©° ë§Žì´ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ìž…ë‹ˆë‹¤.

![Figure 4: SISR(Single Image Super-Resolution).](../../.gitbook/assets/Fig2.PNG)

#### 3) ZSSR(Zero Shot Super-Resolution)
MZSRì˜ Meta-test ë‹¨ê³„ì—ì„œ í™œìš©í•˜ê²Œë  Zero-Shot Super Resolutionì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ZSSR ì•žì„œ ë§ì”€ë“œë¦° SISRê³¼ ë‹¬ë¦¬ í•™ìŠµ ë‹¨ê³„ì—ì„œ ìžê¸° ìžì‹  ì¦‰ internal infromationì„ í•™ìŠµí•©ë‹ˆë‹¤. ìžê¸° ìžì‹  imageë¡œë¶€í„° ì¶”ì¶œëœ HR-LR pairë¥¼ ë§Œë“¤ì–´ í•™ìŠµì„ ì§„í–‰í•˜ê³  ì´ë ‡ê²Œ í•™ìŠµëœ ì •ë³´ë¥¼ í† ëŒ€ë¡œ ì›ë³¸ì„ LRë¡œ ì´ìš©í•˜ì—¬ í™•ëŒ€í•œ ê²°ê³¼ ì¦‰ ì˜ˆì¸¡ì„ ì§„í–‰í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í•œê³„ì ìœ¼ë¡œëŠ” í•œ ìž¥ì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë§Œ í•™ìŠµì„ í•˜ë‹¤ë³´ë‹ˆ í•™ìŠµ ì‹œê°„ì´ ë§Žì´ í•„ìš”í•˜ê³ , ë‹¤ë¥¸ ì´ë¯¸ì§€ì—” ì‚¬ìš© ì–´ë µë‹¤ëŠ” ì ì„ ë³¸ ë…¼ë¬¸ì—ì„œ ì§€ì í•˜ê³  ìžˆìŠµë‹ˆë‹¤.


### Idea

ìžê¸° ìžì‹  imageë¡œë¶€í„° ì¶”ì¶œëœ HR-LR pairë¥¼ ë§Œë“¤ì–´ í•™ìŠµì„ ì§„í–‰í•˜ê³  ì´ë ‡ê²Œ í•™ìŠµëœ ì •ë³´ë¥¼ í† ëŒ€ë¡œ ì›ë³¸ì„ LRë¡œ ì´ìš©í•˜ì—¬ í™•ëŒ€í•œ ê²°ê³¼ë¥¼ í† ëŒ€ë¡œ ì˜ˆì¸¡ì„ ì§„í–‰í•©ë‹ˆë‹¤.
ê·¸ëŸ¬ë‚˜ í•œê³„ì ìœ¼ë¡œëŠ” í•œ ìž¥ì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë§Œ í•™ìŠµì„ í•˜ë‹¤ë³´ë‹ˆ í•™ìŠµì‹œê°„ì´ ë§Žì´ í•„ìš”í•˜ê³ , ë‹¤ë¥¸ ì´ë¯¸ì§€ì—” ì ìš©ì´ ì–´ë µë‹¤ëŠ” ì ì„ ë³¸ ë…¼ë¬¸ì—ì„œ ì§€ì í•˜ê³  ìžˆìŠµë‹ˆë‹¤.
ë”°ë¼ì„œ ì´ ë…¼ë¬¸ì—ì„œëŠ” ë‚´ìš©ì€ MAML(Model-Agnostic Meta-Learning)ì˜ ì ìš©ì„ ì œì•ˆí•©ë‹ˆë‹¤.
MAMLì€ ì ì ˆí•œ ì´ˆê¸° ê°€ì¤‘ì¹˜(weight)ë¥¼ ì°¾ê¸° ìœ„í•œ ë°©ë²•ìž…ë‹ˆë‹¤.
ë‹¤ì–‘í•œ ìž‘ì—…(task)ì— ëŒ€í•´ì„œ ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìžˆëŠ” ê°€ì¤‘ì¹˜ë¥¼ ì°¾ëŠ”ë° ë„ì›€ì„ ì£¼ë©°, Fine-tuningì—ë„ ë„ì›€ì„ ì¤„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

![Figure 5: MAML(Model-Agnostic Meta-Learning) ê°œìš”.](../../.gitbook/assets/Fig5.PNG)
![Figure 6: MAML(Model-Agnostic Meta-Learning) ì•Œê³ ë¦¬ì¦˜.](../../.gitbook/assets/Fig6.PNG)

## 3. Method

![Figure 6: MZSR ê°œë…ë„.](../../.gitbook/assets/Fig7.PNG)

ê·¸ëž˜ì„œ ì´ëŸ¬í•œ CNN ê¸°ë°˜ì˜ ë°©ë²•ê³¼ ZSSRì˜ í•œê³„ì ì„ ê·¹ë³µí•˜ê³ ìž ë³¸ ë…¼ë¬¸ì€ MZSRì„ ì œì•ˆí•©ë‹ˆë‹¤. ì „ì²´ì ì¸ íë¦„ì„ ë³´ì‹œë©´ externel dataë¡œ large scale trainingê³¼ 
meta transfer learningì„ ì§„í–‰í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  Meta-Test ë‹¨ê³„ì—ì„œëŠ” zero-shot super-resolution ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

![Figure 7: MZSR ê°œë…ë„.](../../.gitbook/assets/Fig8.jpg)

Large-scale Trainingë‹¨ê³„ì—ì„œëŠ” ë‹¤ì–‘í•œ ì´ë¯¸ì§€ë¡œë¶€í„° ê³µí†µì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” representationë“¤ì„ í•™ìŠµí•  ìˆ˜ ìžˆë„ë¡ í•©ë‹ˆë‹¤. natural imageë“¤ë¡œ ë¶€í„° íŠ¹ì§•ê°’ë“¤ì„ 
ë°›ì•„ì™€ì„œ í™œìš©í•¨ìœ¼ë¡œì¨ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ë„ë¡ í•©ë‹ˆë‹¤. ìˆ˜ì‹ì„ ë³´ì‹œë©´ ë°”ì´íí”½ìœ¼ë¡œ low resolution imageë¥¼ ë§Œë“¤ì–´ì„œ HR, LR pairë¥¼ ë§Œë“  ë’¤ L1ë¥¼ ì‚¬ìš©í•´ì„œ lossë¥¼
ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ training ì§„í–‰í•©ë‹ˆë‹¤.

![Figure 8: MZSR ê°œë…ë„.](../../.gitbook/assets/Fig9.jpg)

ì´ì œ Meta-Transfer Learning ë‹¨ê³„ìž…ë‹ˆë‹¤. Meta learningì€ í•™ìŠµì„ ìœ„í•œ í•™ìŠµì´ë¼ê³ ë„ í•©ë‹ˆë‹¤. ë‚˜ì¤‘ì— í•™ìŠµì´ ìž˜ ë  ìˆ˜ ìžˆë„ë¡ í•˜ê¸° ìœ„í•´ì„œ
íŠ¹ì •í•œ ê° taskë¡œ ë¹ ë¥´ê²Œ í•™ìŠµë  ìˆ˜ ìžˆë„ë¡ ë§Œë“œëŠ” ê²ƒìž…ë‹ˆë‹¤. ë‹¤ì–‘í•œ kernel conditionì— ê°€ìž¥ sensitiveí•œ initial pointë¥¼ ì°¾ê¸° ìœ„í•´ 
transfer-learningê³¼ optimaization ê¸°ë°˜ì˜ meta-learning ë°©ë²• ì¦‰ MAMLì„ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ì™€ ê°™ì´ taskê°€ 3ê°œê°€ ìžˆë‹¤ê³  í• ë•Œ ê°ê° taskì—
ë§žëŠ” optimalí•œ weightê°’ì€ ì„¸íƒ€1, ì„¸íƒ€2, ì„¸íƒ€3ì´ ìžˆê³   ê°€ ìžˆê³ , í™”ì‚´í‘œ ëìœ¼ë¡œ ë„ë‹¬í•˜ê²Œ ë˜ë©´ ê°ê°ì˜ ê°€ì¤‘ì¹˜ë¡œ ê°€ëŠ” ê° taskì— ëŒ€í•œ lossì˜ ë°©í–¥ì„±ì„ êµ¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
Kernel distributionì„ ìœ„í•´ì„œëŠ” Covariance matrixì„ ì‚¬ìš©í•˜ëŠ”ë°ìš”. ì²˜ìŒ ê´„í˜¸ëŠ” rotation matrixë¡œ ì„¸íƒ€ë§Œí¼ ì´ë¯¸ì§€ë¥¼ íšŒì „í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ëžŒë‹¤ íŒŒë¼ë¯¸í„°ë¥¼
ì‚¬ìš©í•˜ì—¬ ë¸”ëŸ¬ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‹¤ì‹œ ì„¸íƒ€ë§Œí¼ ë°˜ëŒ€ë¡œ íšŒì „ì„ ì‹œì¼œì„œ ì›ë³¸ì´ë¯¸ì§€ë¡œ ë˜ëŒë¦´ ìˆ˜ ìžˆë„ë¡ í•©ë‹ˆë‹¤.

![Figure 9: MZSR ê°œë…ë„.](../../.gitbook/assets/Fig10.jpg)

ì´ì œ ì´ meta-learnerë¥¼ trainì‹œí‚µë‹ˆë‹¤. Task-level Lossë¥¼ í†µí•´ model parameter ðœƒë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  Test errorë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ optimizationì„ ì§„í–‰í•©ë‹ˆë‹¤.

![Figure 10: Super-resolved results of "image050" in Urban100.](../../.gitbook/assets/Fig11.jpg)

ê·¸ ë‹¤ìŒì€ Meta-Test ë‹¨ê³„ìž…ë‹ˆë‹¤. ì´ëŠ” ì•žì„œ ì„¤ëª…ë“œë¦° Zero-shot super learning ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ single image ë‚´ì—ì„œ internal informationì„ í•™ìŠµí•˜ëŠ” ê±¸ ìœ„ ê·¸ë¦¼ì—ì„œ ë³´ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

![Figure 11: MZSR ê°œë…ë„.](../../.gitbook/assets/Fig12.jpg)

ì•žì„œ ì„¤ëª…ë“œë¦° Meta-Transfer Learningê³¼ Meta-Testì˜ ì•Œê³ ë¦¬ì¦˜ìž…ë‹ˆë‹¤. 
Meta-Transfer Learning ì•Œê³ ë¦¬ì¦˜ì„ ë³´ì‹œë©´ Data(D)ê°€ ìžˆì„ ë•Œ ë•Œ LRê³¼ HR batchë¥¼ ë§Œë“  ë‹¤ìŒ L1 Lossë¥¼ ì´ìš©í•´ì„œ Trainingì„ ì§„í–‰í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  task distridution ë‚´ ê° taskì—
ëŒ€í•´ ë‚˜ì¤‘ì— í•™ìŠµì„ ì§„í–‰í–ˆì„ ë•Œ í•™ìŠµì´ ë¹¨ë¦¬ ë  ìˆ˜ ìžˆë„ë¡ meta-learningì„ ì§„í–‰í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ  meta-learnì„ optimizationí•©ë‹ˆë‹¤. 
Meta-Test ë‹¨ê³„ì—ì„œëŠ” í•˜ë‚˜ì˜ ì´ë¯¸ì§€ê°€ ë“¤ì–´ì™”ì„ ë•Œ ê° kernelì— ë§žê²Œ meta-learningì´ ëœ ê°€ì¤‘ì¹˜ ê°’ì„ ë¹ ë¥´ê²Œ update ì‹œí‚µë‹ˆë‹¤. ì´ëŸ° ê³¼ì •ì„ í†µí•´ SRì´ë¯¸ì§€ë¥¼ return í•˜ëŠ” ê±¸ ë³´ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

## 4. Experiment & Result

![Figure 12: Bicubic Downsampling ì‹¤í—˜ ê²°ê³¼.](../../.gitbook/assets/Fig13.PNG)

ë°”ì´íë¹…ìœ¼ë¡œ ë‹¤ìš´ìƒ˜í”Œë§ëœ ë°ì´í„°ì…‹ì˜ ì‹¤í—˜ ê²°ê³¼ìž…ë‹ˆë‹¤. ì•„ë¬´ëž˜ë„ ë°”ì´íë¹… ë‹¤ìš´ìƒ˜í”Œë§ì„ ì§„í–‰í–ˆê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë¹„êµí–ˆì„ ë•Œ
MZSRì´ ë¹„êµì  ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ë°ì´í„°ì…‹ì´ ìžˆì§€ë§Œ 1-10ë²ˆì˜ ì—…ë°ì´íŠ¸ë§Œìœ¼ë¡œ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìžˆìŒì„ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

![Figure 13: ë‹¤ì–‘í•œ ì»¤ë„ì„ ì‚¬ìš©í•œ ì‹¤í—˜ ê²°ê³¼.](../../.gitbook/assets/Fig14.PNG)

í•´ë‹¹ í…Œì´ë¸”ì€ ë‹¤ì–‘í•œ ì»¤ë„ì„ ì‚¬ìš©í•œ ì‹¤í—˜ ê²°ê³¼ìž…ë‹ˆë‹¤. ë¹¨ê°„ìƒ‰ì´ 1ìœ„, íŒŒëž€ìƒ‰ì´ 2ìœ„ ê²°ê³¼ì¸ë°, ëŒ€ë¶€ë¶„ unsupervised ë°©ë²•ì´ 
ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ë©° MZSRì˜ ê²½ìš° 10ë²ˆë§Œ ì—…ë°ì´íŠ¸í•œ ì‹¤í—˜ê²°ê³¼ì—ì„œëŠ” ëŒ€ë¶€ë¶„ 1, 2ìœ„ë¥¼ ì°¨ì§€í•œ ê²ƒì„ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

![Figure 14: ì‹¤í—˜ ê²°ê³¼ ë° ìˆ˜ì¹˜ ì‹œê°í™”(1).](../../.gitbook/assets/Fig15.PNG)

ì´ëŸ¬í•œ ìˆ˜ì¹˜ë¥¼ ì‹œê°í™”í•œ ê²°ê³¼ìž…ë‹ˆë‹¤. MZSRì„ 10ë²ˆë§Œ ì—…ë°ì´íŠ¸ í–ˆìŒì—ë„ ìš°ìˆ˜í•œ ë³µì› ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. 

![Figure 15: ì‹¤í—˜ ê²°ê³¼ ë° ìˆ˜ì¹˜ ì‹œê°í™”(2).](../../.gitbook/assets/Fig16.PNG)

ì—¬ê¸°ë„ ë§ˆì°¬ê°€ì§€ë¡œ í•´ë‹¹ ì»¤ë„ conditionì—ì„œë„ MZSRì€ 10ë²ˆë§Œ ì—…ë°ì´íŠ¸ í–ˆìŒì—ë„ ìš°ìˆ˜í•œ ë³µì› ì„±ëŠ¥ì„ ë³´ì´ê³  ìžˆìŒì„ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤. 

### Experimental setup

* Datasetìœ¼ë¡œëŠ” Set5, BSD100, Urban100ì„ ì €í•´ìƒë„ë¡œ ë³€í™˜í•œ ì´ë¯¸ì§€, ê·¸ë¦¬ê³  ì›ë³¸ì„ ì´ìš©í–ˆìŠµë‹ˆë‹¤.
* ë¹„êµëŒ€ìƒìœ¼ë¡œëŠ” Bicubic, CARN, RCAN, ZSSRì„ ì´ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
* Training ì„¸íŒ…ì€ Î± = 0.01 and Î² = 0.0001 ìœ¼ë¡œ ì„¤ì •í•˜ì˜€ìŠµë‹ˆë‹¤.
* ê²°ê³¼ëŠ” YCbCr color ê³µê°„ì˜ Y channelì—ì„œ PSNR(dB)ê³¼ SSIMì˜ í‰ê· ì„ ë‚¸ ê°’ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤. ë¹¨ê°„ìƒ‰ì€ ìµœìƒì˜ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ê³  íŒŒëž€ìƒ‰ì€ ì°¨ì„ ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. 
ë˜í•œ ê´„í˜¸ ì•ˆì˜ ìˆ«ìžëŠ” ì´ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” MZSRë°©ë²•ì˜ ê·¸ë ˆì´ë””ì–¸íŠ¸ ì—…ë°ì´íŠ¸ì˜ ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

### Result

![Figure 16: MZSR ë° ë‹¤ë¥¸ Baselineì˜ ì„±ëŠ¥ ë¹„êµ.](../../.gitbook/assets/Fig17.jpg)

MZSRì˜ ê²½ìš° í•œ ë²ˆì˜ gradient updateë§Œìœ¼ë¡œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ìž„ì„ ì•žì„œ ì–¸ê¸‰í–ˆìŠµë‹ˆë‹¤.
ê·¸ë¦¼ì„ ë³´ì‹œë©´ initial pointì—ì„œëŠ” ê°€ìž¥ ì•ˆ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìžˆì—ˆìŠµë‹ˆë‹¤.
ê·¸ëŸ¬ë‚˜ ì´ì™€ ê°™ì´ 1ë²ˆì˜ ì—…ë°ì´íŠ¸ë§Œìœ¼ë¡œ ë‹¤ë¥¸ pre-trained networkìœ¼ë¡œ ë³µì›ëœ ì´ë¯¸ì§€ë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìžˆìŒì„ í™•ì¸í•  ìˆ˜ ìžˆëŠ”ë°ìš”,
ì´ëŠ” ì–¼ë§ˆë‚˜ MZSRì´ ë¹ ë¥¸ ì ì‘ ëŠ¥ë ¥ì´ ìžˆëŠ”ì§€ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

![Figure 17: MZSR ë° Bicubic interpolationì˜ ì„±ëŠ¥ ë¹„êµ.](../../.gitbook/assets/Fig18.PNG)

ë˜í•œ, MZSRì€ ìžê¸° ìžì‹ ìœ¼ë¡œë¶€í„° í•™ìŠµì„ ì§„í–‰í•˜ê¸° ë•Œë¬¸ì— ì˜¤ë¥¸ìª½ ê·¸ë¦¼ê³¼ ê°™ì´ multi-scale recurrent patternsì„ ê°€ì§„ ì´ë¯¸ì§€ì—ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ 


## 5. Conclusion
ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì™¸ë¶€ ìƒ˜í”Œê³¼ ë‚´ë¶€ ìƒ˜í”Œì„ ëª¨ë‘ í™œìš©í•˜ì—¬ ë¹ ë¥´ê³  ìœ ì—°í•˜ë©° ê°€ë²¼ìš´ ìžì²´ ê°ë… ì´ˆí•´ìƒë„ ë°©ë²•ì„ ì œì‹œí•˜ì˜€ìŠµë‹ˆë‹¤.
êµ¬ì²´ì ìœ¼ë¡œ, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Blur kernalì˜ ë‹¤ì–‘í•œ ì¡°ê±´ì— ë¯¼ê°í•œ ì´ˆê¸° ê°€ì¤‘ì¹˜ë¥¼ ì°¾ê¸° ìœ„í•´ Transfer Learningê³¼ í•¨ê»˜ ìµœì í™” ê¸°ë°˜ Meta Learningì„ ì´ìš©í•©ë‹ˆë‹¤.
ë”°ë¼ì„œ ë³¸ ë…¼ë¬¸ì—ì„œì˜ ë°©ë²•ì€ ëª‡ ê°€ì§€ ê·¸ë¼ë°ì´ì…˜ ì—…ë°ì´íŠ¸ ë‚´ì—ì„œ íŠ¹ì • ì´ë¯¸ì§€ ì¡°ê±´ì— ë¹ ë¥´ê²Œ ì ì‘í•  ìˆ˜ ìžˆë‹¤ëŠ” ê²ƒì´ ìž¥ì ìž…ë‹ˆë‹¤. ê´‘ë²”ìœ„í•œ ì‹¤í—˜ì„ í†µí•´ MZSRì´ ìˆ˜ì²œ ë²ˆì˜ 
ê²½ì‚¬ í•˜ê°• ë°˜ë³µì´ í•„ìš”í•œ ZSSRì„ í¬í•¨í•œ ë‹¤ë¥¸ ë°©ë²•ë³´ë‹¤ ìš°ìˆ˜í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¤ë§Œ ë„¤íŠ¸ì›Œí¬ ë„¤íŠ¸ì›Œí¬ ëª¨í˜•, í•™ìŠµ ì „ëžµ, multi-scale ëª¨ë¸ ë“± ìž‘ì—…ì—ì„œ ê°œì„ í•  ë¶€ë¶„ì´ ë§Žì€ ê²ƒìœ¼ë¡œ ë³´ìž…ë‹ˆë‹¤..
ê²°ë¡ ì ìœ¼ë¡œ MZSRì€ internalê³¼ external ìƒ˜í”Œì„ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ ì ì€ ì—…ë°ì´íŠ¸ë¡œë§Œìœ¼ë¡œ í•´ìƒë„ ë³µì›ì„ ìˆ˜í–‰í•˜ê²Œ í•˜ëŠ” ë¹ ë¥´ê³  flexibleí•œ ë°©ë²•ì´ë¼ê³  ë§ì”€ë“œë¦´ ìˆ˜ìžˆìŠµë‹ˆë‹¤.

### Take home message \(ì˜¤ëŠ˜ì˜ êµí›ˆ\)

> ì¡°ê¸ˆ ë” ì°½ì˜ì ì¸ ìƒê°ì„ í•  ìˆ˜ ìžˆëŠ” ì‚¬ëžŒì´ ë˜ìž.
>
> Transfer learningê³¼ Meta learningì˜ ì¡°í•©ì€ ë‹¤ë¥¸ ë¶„ì•¼ë¡œ ì—°ê²°ë  ìˆ˜ ìžˆì„ë§Œí¼ ê·¸ ì˜í–¥ë ¥ì´ ë§‰ì¤‘í•˜ë‹¤.
>

## Author / Reviewer information

### Author

**ë°±ì •ì—½ \(Jeongyeop Baek\)** 

* M.S. student, Civil & Engineering Department, KAIST (Advisor: Seongju Chang)
* Interested in occupant-centric HVAC control based on individual thermal comfort  
* jungyubaik@kaist.ac.kr
* https://baekkkkk96.tistory.com/

### Reviewer

1. Korean name \(English name\): Affiliation / Contact information
2. Korean name \(English name\): Affiliation / Contact information
3. ...

## Reference & Additional materials

1. Jae Woong Soh, Sunwoo Cho, Namik Cho. Meta-Transfer Learning for Zero-shot Super Resolution. In CVPR, 2020.
2. Official GitHub repository :  https://www.github.com/JWSoh/MZSR.
3. Eirikur Agustsson and Radu Timofte. Ntire 2017 challenge on single image super-resolution: Dataset and
study. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 126â€“135, 2017.
4. Namhyuk Ahn, Byungkon Kang, and Kyung-Ah Sohn. Fast, accurate, and lightweight super-resolution with cascading residual network. In Proceedings
of the European Conference on Computer Vision(ECCV), pages 252â€“268, 2018.
5. Antreas Antoniou, Harrison Edwards, and Amos Storkey. How to train your maml. In ICLR, 2019.

